{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:21:01.388209Z\",\"iopub.execute_input\":\"2024-06-29T07:21:01.388489Z\",\"iopub.status.idle\":\"2024-06-29T07:21:01.403224Z\",\"shell.execute_reply.started\":\"2024-06-29T07:21:01.388464Z\",\"shell.execute_reply\":\"2024-06-29T07:21:01.402328Z\"}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\n\nimport re\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:21:01.458612Z\",\"iopub.execute_input\":\"2024-06-29T07:21:01.458896Z\",\"iopub.status.idle\":\"2024-06-29T07:21:02.069278Z\",\"shell.execute_reply.started\":\"2024-06-29T07:21:01.458872Z\",\"shell.execute_reply\":\"2024-06-29T07:21:02.068329Z\"}}\n# read the data\ndf=pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n# get first 5 rows\ndf.head()\nprint(df['sentiment'].unique())\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:21:02.071302Z\",\"iopub.execute_input\":\"2024-06-29T07:21:02.071676Z\",\"iopub.status.idle\":\"2024-06-29T07:21:02.148311Z\",\"shell.execute_reply.started\":\"2024-06-29T07:21:02.071641Z\",\"shell.execute_reply\":\"2024-06-29T07:21:02.147394Z\"}}\n# Strip any leading/trailing whitespace and convert to lowercase if necessary\ndf['sentiment'] = df['sentiment'].str.strip().str.lower()\n\n# Check unique values again\nprint(df['sentiment'].unique())\n\n# Now apply the mapping\n# df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n\ndf[\"sentiment\"]=df[\"sentiment\"].apply(lambda x: 1 if x == 'positive' else 0)\ndf.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:21:01.301068Z\",\"iopub.execute_input\":\"2024-06-29T07:21:01.301398Z\",\"iopub.status.idle\":\"2024-06-29T07:21:01.307145Z\",\"shell.execute_reply.started\":\"2024-06-29T07:21:01.301371Z\",\"shell.execute_reply\":\"2024-06-29T07:21:01.306157Z\"}}\ndef clean_data(text):\n    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n    text = re.sub(r'[^a-zA-Z]', ' ', text) \n    text=text.lower()\n    text=text.split()\n    text=[word for word in text if word not in stopwords.words('english')]\n    text=\" \".join(text)\n    return text\n    \n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:21:02.149355Z\",\"iopub.execute_input\":\"2024-06-29T07:21:02.149622Z\",\"iopub.status.idle\":\"2024-06-29T07:43:59.390694Z\",\"shell.execute_reply.started\":\"2024-06-29T07:21:02.149598Z\",\"shell.execute_reply\":\"2024-06-29T07:43:59.389826Z\"}}\ndf['cleaned_review']=df['review'].apply(clean_data)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:43:59.393023Z\",\"iopub.execute_input\":\"2024-06-29T07:43:59.393309Z\",\"iopub.status.idle\":\"2024-06-29T07:43:59.412979Z\",\"shell.execute_reply.started\":\"2024-06-29T07:43:59.393284Z\",\"shell.execute_reply\":\"2024-06-29T07:43:59.412167Z\"}}\n# look if things are set properly\ndf[df['sentiment']==1]\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:43:59.414050Z\",\"iopub.execute_input\":\"2024-06-29T07:43:59.414366Z\",\"iopub.status.idle\":\"2024-06-29T07:43:59.429694Z\",\"shell.execute_reply.started\":\"2024-06-29T07:43:59.414336Z\",\"shell.execute_reply\":\"2024-06-29T07:43:59.428782Z\"}}\n\nfrom sklearn.model_selection import train_test_split\nX=df[\"cleaned_review\"]\ny=df[\"sentiment\"]\n\ntrain_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=52)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:43:59.431023Z\",\"iopub.execute_input\":\"2024-06-29T07:43:59.431678Z\",\"iopub.status.idle\":\"2024-06-29T07:44:06.365509Z\",\"shell.execute_reply.started\":\"2024-06-29T07:43:59.431629Z\",\"shell.execute_reply\":\"2024-06-29T07:44:06.364717Z\"}}\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# TF-IDF (term frequency inverse document frequency)\n# without doing this step you wont be able to train the model as \n# the training data is in text format it is needs to be converted into numerical\n\nvectorizer=TfidfVectorizer(max_features=6000)\nx_train_tfidf=vectorizer.fit_transform(train_x)\nx_test_tfidf=vectorizer.fit_transform(test_x)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:44:06.366678Z\",\"iopub.execute_input\":\"2024-06-29T07:44:06.366962Z\",\"iopub.status.idle\":\"2024-06-29T07:44:06.371194Z\",\"shell.execute_reply.started\":\"2024-06-29T07:44:06.366937Z\",\"shell.execute_reply\":\"2024-06-29T07:44:06.370301Z\"}}\nfrom sklearn.linear_model import LogisticRegression\n\nlr=LogisticRegression()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:44:06.372465Z\",\"iopub.execute_input\":\"2024-06-29T07:44:06.372766Z\",\"iopub.status.idle\":\"2024-06-29T07:44:07.575332Z\",\"shell.execute_reply.started\":\"2024-06-29T07:44:06.372741Z\",\"shell.execute_reply\":\"2024-06-29T07:44:07.574600Z\"}}\nmodel=lr.fit(x_train_tfidf,train_y)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T07:44:07.576527Z\",\"iopub.execute_input\":\"2024-06-29T07:44:07.576906Z\",\"iopub.status.idle\":\"2024-06-29T07:44:07.582815Z\",\"shell.execute_reply.started\":\"2024-06-29T07:44:07.576874Z\",\"shell.execute_reply\":\"2024-06-29T07:44:07.581855Z\"}}\ny_pred=model.predict(x_test_tfidf)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-06-29T08:23:15.891633Z\",\"iopub.execute_input\":\"2024-06-29T08:23:15.892556Z\",\"iopub.status.idle\":\"2024-06-29T08:23:15.909430Z\",\"shell.execute_reply.started\":\"2024-06-29T08:23:15.892523Z\",\"shell.execute_reply\":\"2024-06-29T08:23:15.908510Z\"}}\n# check the accuracy of the model\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\nacc=accuracy_score(test_y,y_pred)\npre_c=precision_score(test_y,y_pred)\nf1_scr=f1_score(test_y,y_pred)\nprint(acc,pre_c,f1_scr)","metadata":{"_uuid":"ca3f2e83-92fe-4673-9acc-0bef1d7a82e2","_cell_guid":"cd5e6d0c-a53d-4040-8756-221db29fd208","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}